{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "\n",
    "\n",
    "import requests\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESTARTING... LET'S TRY USING THE API\n",
    "Statistical methods like topic modelling probably should really be used with large volumes of data.\n",
    "To keep this example reasonably small (and therefore fast) we'll try to work with a smallish set of books that is large enough to work reasonably well.\n",
    "To begin with, we'll use the catalogue API to search for \"typhoid\".\n",
    "\n",
    "(see https://developers.wellcomecollection.org/docs/examples for much more about working with the API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "catalogue_base_url = 'https://api.wellcomecollection.org/catalogue/v2/'\n",
    "\n",
    "response = requests.get(\n",
    "    catalogue_base_url + 'works',\n",
    "    params={\n",
    "        'include': 'identifiers,subjects,production',\n",
    "        'pageSize': 100,\n",
    "        'query': 'typhoid',\n",
    "    },\n",
    ")\n",
    "if response.status_code != 200:\n",
    "  print('error', file = sys.stderr)\n",
    "response_data = response.json()\n",
    "for k, v in response_data.items():\n",
    "    if k == 'results': continue #there will be loads of this\n",
    "    print(f'{k}: {v}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I ran this code, I got 1099 `totalResults`. Your results may differ, depending upon how Wellcome's collection has changed in the meantime. Anyway, this feels like a nice number of texts to start working with. Let's learn some more about them. We'll start by downloading the catalogue data for all of the pages of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "#let's have a progress bar\n",
    "catalogue_bar = tqdm(\n",
    "  unit = 'pages',\n",
    "  total = response_data['totalPages'],\n",
    "  desc = 'downloading catalogue data',\n",
    ")\n",
    "\n",
    "#We already got the first page of results in the previous cell\n",
    "catalogue_bar.update(1)\n",
    "works = response_data['results']\n",
    "\n",
    "#Now we'll add all of the other pages of results to the list \"works\"\n",
    "while 'nextPage' in response_data:\n",
    "  response = requests.get(response_data['nextPage'])\n",
    "  catalogue_bar.update(1)\n",
    "  if response.status_code != 200:\n",
    "    print('error', file = sys.stderr)\n",
    "  response_data = response.json()\n",
    "  works.extend(response_data['results'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all of the catalogue data for our \"typhoid\" works, let's get a sense of what this covers. We'll just look at the contents of the first record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import JSON as json_display\n",
    "json_display(works[0], expanded = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite a lot of data! We are interested in text about typhoid, so let's focus on the type of work that this is (is it something written, or something else, like a drawing or a photograph?) and the subject matter. We can use JSONPath to look this up.\n",
    "\n",
    "We'll start with the \"type\" of the work. The last entry in the above JSON is workType. The label and type look relevant. Let's examine the values that these can take across the whole collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".... might want to add a cell about filtering out non-Wellcome items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jsonpath_ng.ext import parse as json_parse\n",
    "from collections import Counter\n",
    "\n",
    "def count(query, data_list):\n",
    "  empty = 0\n",
    "  counter = Counter()\n",
    "  searcher = json_parse(query)\n",
    "  for datum in data_list:\n",
    "    results = searcher.find(datum)\n",
    "    if len(results) == 0:\n",
    "      empty += 1\n",
    "    else:\n",
    "      for result in results: #we should have a list of DatumInContext\n",
    "                             #this function assumes the value will be hashable, so it does not handle all queries\n",
    "                             #for example, it will not work if \"value\" is a dict or a list\n",
    "        counter[result.value] += 1\n",
    "  return empty, counter\n",
    "\n",
    "def dumpCount(query, data_list, min_proportion = 0):\n",
    "  emptyCount, counter = count(query, data_list)\n",
    "  total = len(data_list)\n",
    "  below_min = 0\n",
    "  for k, v in counter.most_common():\n",
    "    proportion = v/total\n",
    "    if proportion >= min_proportion:\n",
    "      print(f'{v:4}/{total} ({100 * v/total:3.0f}%) {k}')\n",
    "    else:\n",
    "      below_min += 1\n",
    "  if below_min > 0:\n",
    "    print(f'{below_min} results hidden as below minimum proportion of {min_proportion * 100:.0f}%')\n",
    "  if emptyCount > 0:\n",
    "    print(f'{emptyCount:4}/{total} ({100 * emptyCount/total:3.0f}%) have no value')\n",
    "\n",
    "print('workType types:')\n",
    "dumpCount('$.workType.type', works)\n",
    "print()\n",
    "print('workType labels:')\n",
    "dumpCount('$.workType.label', works)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are a range of types of works in our results. At the time of writing, 3/4 of the works are books and several others are of types that could reasonably have text (e.g. \"Archives and manuscripts\", \"Student dissertations\", \"E-books\", \"Manuscripts\", \"Journals\".\n",
    "\n",
    "Given that text is provided by an OCR pipeline, it is only printed texts that are likely to have online text available. So we filter down (for now) to just books, e-books and journals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is quite Pythonic, but essentially is filtering works down to a list of just\n",
    "#books, e-books and journals. We cannot use JSONPath to do this because JSONPath\n",
    "#can only check values for the purpose of filtering lists, and works appears to\n",
    "#JSONPath code as single JSON objects (re e.g. https://stackoverflow.com/a/43737750)\n",
    "\n",
    "printed_works = list(filter(lambda x: x['workType']['label'] == 'Books' or\n",
    "                                      x['workType']['label'] == 'E-books' or\n",
    "                                      x['workType']['label'] == 'Journals', works))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working out the catalogue subject of a work is more complicated. Works in Wellcome Collection are classified according to a range of schemes. If we look in the above JSON, we can also see that the structure is fairly complex, involving a mixture of \"Subjects\" and \"Concepts\". Rather than unpick all this, we'll just look at a part of the structure to get a sense of how things are classified. We'll stick with the printed works here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Subjects')\n",
    "#label of every member of the subjects array which has a type of Subject\n",
    "dumpCount('$.subjects[?(@.type==\"Subject\")].label', printed_works, 0.02)\n",
    "\n",
    "print()\n",
    "print('Concepts')\n",
    "#label of every node at any depth beneath subjects which has a type of concept\n",
    "dumpCount('$.subjects..*[?(@.type==\"Concept\")].label', printed_works, 0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[This text applied to running the above cell on all works. If I stick with the printed_works version then it will need updating.]\n",
    "\n",
    "Straight away, we can see that both Subjects and Concepts are not available for about 1/5 of the collection (e.g. 204/1100 ( 19%) have no value).\n",
    "\n",
    "We can also see that there are a lot of possible values here -- so many that I've written the code to hide all results applying to less than 2% of the works on typhoid.\n",
    "\n",
    "We can also see that the phrase \"typhoid fever\" (with varying capitalization) covers 50% of the Subjects and 63% of the Concepts. This suggests that these specific values will get pretty good results in a search. What we cannot tell from this is how many of the works covered by other concepts are actually relevant.\n",
    "\n",
    "[This could be a good place to introduce the difference between Wellcome and non-Wellcome works and to see what effect filtering down to just Wellcome has.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One difficulty may be that Wellcome's catalogue includes texts not held by Wellcome. These have the potential to be classified differently.\n",
    "\n",
    "So let's assume that we are interested in searching works actually held by Wellcome itself and limit down to them.\n",
    "\n",
    "The way that was suggested to me to do this was to look for works held on either open shelves or in closed stores. This seems to make sense, although perhaps it needs a tweak for purely digital works such as E-books.\n",
    "\n",
    "For purposes of this notebook we won't worry about purely digital works, so lets filter down. For this purpose, we'll work with all format types again (not just printed works)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All availability ids:')\n",
    "dumpCount('$.availabilities[*].id', works)\n",
    "print()\n",
    "\n",
    "open_searcher   = json_parse(\"$.availabilities[?(@.id=='open-shelves')].id\")\n",
    "closed_searcher = json_parse(\"$.availabilities[?(@.id=='closed-stores')].id\")\n",
    "\n",
    "wellcome_works = list(filter(lambda x: len(open_searcher.find(x)) > 0 or len(closed_searcher.find(x)) > 0, works))\n",
    "print(f'{len(wellcome_works)}/{len(works)} works are available in closed and/or open stores (therefore held by Wellcome itself)')\n",
    "\n",
    "wellcome_printed = list(filter(lambda x: x['workType']['label'] == 'Books' or\n",
    "                                         x['workType']['label'] == 'E-books' or\n",
    "                                         x['workType']['label'] == 'Journals', wellcome_works))\n",
    "print(f'{len(wellcome_printed)} of these are *printed* works that may have OCR text available. These break down as:')\n",
    "dumpCount('$.workType.label', wellcome_printed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have done this, we can look again at concepts and subjects, to see what the coverage is like for the particular works that we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Subjects')\n",
    "#label of every member of the subjects array which has a type of Subject\n",
    "dumpCount('$.subjects[?(@.type==\"Subject\")].label', wellcome_printed, 0.02)\n",
    "\n",
    "print()\n",
    "print('Concepts')\n",
    "#label of every node at any depth beneath subjects which has a type of concept\n",
    "dumpCount('$.subjects..*[?(@.type==\"Concept\")].label', wellcome_printed, 0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that [analysis may change as I fiddle things around] the subjects \"Typhoid Fever - epidemiology\" and \"Typhoid fever\" cover 58% of our original search results as filtered down to printed texts held at Wellcome, or 76% for the concept \"Typhoid Fever\". Around 15% of works have neither subject nor concept, indicating that this is not explained only by a work not being held at Wellcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also get a sense of when and where these works were published."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dates (by frequency)\")\n",
    "dumpCount('$.production[*].dates[*].label', wellcome_printed)\n",
    "print()\n",
    "print(\"Dates (roughly ordered)\")\n",
    "empty, counter = count('$.production[*].dates[*].label', wellcome_printed)\n",
    "print(sorted(counter.elements()))\n",
    "print()\n",
    "print(\"Places\")\n",
    "dumpCount('$.production[*].places[*].label', wellcome_printed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import re\n",
    "import math\n",
    "\n",
    "\n",
    "print('Rough chart of cumulative dates')\n",
    "\n",
    "#Just grab the dates that are easy to pick up\n",
    "#This code will skip over an opening square bracket if there is one, then grab a 4 digit number if there is one\n",
    "#Otherwise it will reject the date as unusable\n",
    "#This means for example that '18' would be rejected\n",
    "#While '1900-1920' would be turned into just '1900'\n",
    "mismatch = 0\n",
    "searcher = json_parse('$.production[*].dates[*].label')\n",
    "matcher = re.compile(r'\\s*\\[?(\\d{4})(?:\\D|$)')\n",
    "filtered_results = Counter()\n",
    "for work in wellcome_printed:\n",
    "  results = searcher.find(work)\n",
    "\n",
    "  #a work may have more than one date, we just take the earliest one\n",
    "  first_date = 99999 #a 4 digit number must be lower than this\n",
    "  for result in results:\n",
    "    match = matcher.match(result.value)\n",
    "    if match:\n",
    "      x = int(match.group(1))\n",
    "      if x < first_date:\n",
    "        first_date = x\n",
    "  if first_date == 99999: #no date found\n",
    "    mismatch += 1\n",
    "  else:\n",
    "    filtered_results[first_date] += 1\n",
    "\n",
    "filtered_results = sorted(filtered_results.items())\n",
    "first_year = filtered_results[0][0]\n",
    "final_year = filtered_results[-1][0]\n",
    "total = 0\n",
    "cumulative = {}\n",
    "for year, count in filtered_results:\n",
    "  total += count\n",
    "  cumulative[year] = total\n",
    "rounded_up_total = math.ceil(total / 100.0) * 100\n",
    "\n",
    "ax = seaborn.lineplot(cumulative)\n",
    "ax.set(\n",
    "  xlabel = 'Year',\n",
    "  ylabel = 'Total works',\n",
    "  ylim = (0, rounded_up_total),\n",
    ")\n",
    "plt.show()\n",
    "print(f'{mismatch} works have no usable date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have explored what the catalogue can tell us a little, and got a rough sense of the range of texts that we might be able to work with. The next step is to find out which ones actually have digitised text available."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
