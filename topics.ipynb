{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the data... there is an API, but it limits to 10,000 results... in any case, it is straightforward to work with a snapshot... we can use some lightly adapted code from https://developers.wellcomecollection.org/docs/examples/working-with-snapshots-of-the-api to acquire the snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "import gzip\n",
    "import os\n",
    "import io\n",
    "\n",
    "snapshot_url = \"https://data.wellcomecollection.org/catalogue/v2/works.json.gz\"\n",
    "\n",
    "data_dir = Path(\"./data\").resolve()\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "file_name = Path(snapshot_url).parts[-1]\n",
    "zipped_path = data_dir / file_name\n",
    "unzipped_path = zipped_path.with_suffix(\"\")\n",
    "\n",
    "# check whether the file already exists before doing any work\n",
    "if not unzipped_path.exists():\n",
    "  if not zipped_path.exists():\n",
    "\n",
    "    # make a request to the snapshot URL and stream the response\n",
    "    r = requests.get(snapshot_url, stream=True)\n",
    "    \n",
    "    # use the length of the response to create a progress bar for the download\n",
    "    download_progress_bar = tqdm(\n",
    "      unit=\"bytes\",\n",
    "      total=int(r.headers[\"Content-Length\"]),\n",
    "      desc=f\"Downloading {file_name}\",\n",
    "    )\n",
    "\n",
    "    # write the streamed response to our file in chunks of 1024 bytes\n",
    "    with open(zipped_path, \"wb\") as f:\n",
    "      for chunk in r.iter_content(chunk_size=1024):\n",
    "        if chunk:\n",
    "          f.write(chunk)\n",
    "          download_progress_bar.update(len(chunk))\n",
    "\n",
    "      download_progress_bar.close()\n",
    "\n",
    "  # open the zipped file, and the unzipped file\n",
    "  with gzip.open(zipped_path, \"rb\") as f_in, open(unzipped_path, \"wb\") as f_out:\n",
    "    unzip_progress_bar = tqdm(\n",
    "      unit=\"bytes\",\n",
    "      total=f_in.seek(0, io.SEEK_END), # measure the unzipped length of the zipped file using `.seek()`\n",
    "      desc=f\"unzipping {file_name}\",\n",
    "    )\n",
    "\n",
    "    # we used `.seek()` to move the cursor to the end of the file, so we need to\n",
    "    # move it back to the start before we start reading\n",
    "    f_in.seek(0)\n",
    "\n",
    "    # read the zipped file in chunks of 1MB\n",
    "    for chunk in iter(lambda: f_in.read(1024 * 1024), b\"\"):\n",
    "      f_out.write(chunk)\n",
    "      unzip_progress_bar.update(len(chunk))\n",
    "\n",
    "    unzip_progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
